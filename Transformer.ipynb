{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [TRANSFORMERS](https://towardsdatascience.com/build-your-own-transformer-from-scratch-using-pytorch-84c850470dcb)","metadata":{}},{"cell_type":"markdown","source":"# IMPORTING NECESSARY LIBRARIES","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport math\nimport copy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.168206Z","iopub.execute_input":"2024-11-15T13:19:54.168685Z","iopub.status.idle":"2024-11-15T13:19:54.174894Z","shell.execute_reply.started":"2024-11-15T13:19:54.168640Z","shell.execute_reply":"2024-11-15T13:19:54.173532Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# DATA MOCKING","metadata":{}},{"cell_type":"code","source":"src_vocab_size = 5000\ntgt_vocab_size = 5000\nd_model = 512\nnum_heads = 8\nnum_layers = 6\nd_ff = 2048\nmax_seq_length = 100\ndropout = 0.1\n\n# Generate random sample data\nsrc_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\ntgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.176887Z","iopub.execute_input":"2024-11-15T13:19:54.177275Z","iopub.status.idle":"2024-11-15T13:19:54.227676Z","shell.execute_reply.started":"2024-11-15T13:19:54.177237Z","shell.execute_reply":"2024-11-15T13:19:54.226444Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# MULTIHEAD ATTENTION","metadata":{}},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, d_model, num_heads):\n        super(MultiHeadAttention, self).__init__()\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.d_k = d_model // num_heads\n        \n        self.W_q = nn.Linear(d_model, d_model)\n        self.W_k = nn.Linear(d_model, d_model)\n        self.W_v = nn.Linear(d_model, d_model)\n        self.W_o = nn.Linear(d_model, d_model)\n        \n    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n        if mask is not None:\n            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n        attn_probs = torch.softmax(attn_scores, dim=-1)\n        output = torch.matmul(attn_probs, V)\n        return output\n        \n    def split_heads(self, x):\n        batch_size, seq_length, d_model = x.size()\n        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n        \n    def combine_heads(self, x):\n        batch_size, _, seq_length, d_k = x.size()\n        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n        \n    def forward(self, Q, K, V, mask=None):\n        Q = self.split_heads(self.W_q(Q))\n        K = self.split_heads(self.W_k(K))\n        V = self.split_heads(self.W_v(V))\n        \n        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n        output = self.W_o(self.combine_heads(attn_output))\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.229102Z","iopub.execute_input":"2024-11-15T13:19:54.229554Z","iopub.status.idle":"2024-11-15T13:19:54.245569Z","shell.execute_reply.started":"2024-11-15T13:19:54.229501Z","shell.execute_reply":"2024-11-15T13:19:54.244390Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Position-wise Feed-Forward Networks","metadata":{}},{"cell_type":"code","source":"class PositionWiseFeedForward(nn.Module):\n    def __init__(self, d_model, d_ff):\n        super(PositionWiseFeedForward, self).__init__()\n        self.fc1 = nn.Linear(d_model, d_ff)\n        self.fc2 = nn.Linear(d_ff, d_model)\n        self.relu = nn.ReLU()\n\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.248144Z","iopub.execute_input":"2024-11-15T13:19:54.248543Z","iopub.status.idle":"2024-11-15T13:19:54.263155Z","shell.execute_reply.started":"2024-11-15T13:19:54.248503Z","shell.execute_reply":"2024-11-15T13:19:54.262092Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Positional Encoding","metadata":{}},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_seq_length):\n        super(PositionalEncoding, self).__init__()\n        \n        pe = torch.zeros(max_seq_length, d_model)\n        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n        \n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        \n        self.register_buffer('pe', pe.unsqueeze(0))\n        \n    def forward(self, x):\n        return x + self.pe[:, :x.size(1)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.264776Z","iopub.execute_input":"2024-11-15T13:19:54.265222Z","iopub.status.idle":"2024-11-15T13:19:54.277306Z","shell.execute_reply.started":"2024-11-15T13:19:54.265170Z","shell.execute_reply":"2024-11-15T13:19:54.276019Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# ENCODER LAYER","metadata":{}},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout):\n        super(EncoderLayer, self).__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, mask):\n        attn_output = self.self_attn(x, x, x, mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        ff_output = self.feed_forward(x)\n        x = self.norm2(x + self.dropout(ff_output))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.278600Z","iopub.execute_input":"2024-11-15T13:19:54.278980Z","iopub.status.idle":"2024-11-15T13:19:54.296035Z","shell.execute_reply.started":"2024-11-15T13:19:54.278938Z","shell.execute_reply":"2024-11-15T13:19:54.294910Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"# DECODER LAYER","metadata":{}},{"cell_type":"code","source":"class DecoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ff, dropout):\n        super(DecoderLayer, self).__init__()\n        self.self_attn = MultiHeadAttention(d_model, num_heads)\n        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n        self.norm1 = nn.LayerNorm(d_model)\n        self.norm2 = nn.LayerNorm(d_model)\n        self.norm3 = nn.LayerNorm(d_model)\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x, enc_output, src_mask, tgt_mask):\n        attn_output = self.self_attn(x, x, x, tgt_mask)\n        x = self.norm1(x + self.dropout(attn_output))\n        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n        x = self.norm2(x + self.dropout(attn_output))\n        ff_output = self.feed_forward(x)\n        x = self.norm3(x + self.dropout(ff_output))\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.298108Z","iopub.execute_input":"2024-11-15T13:19:54.298647Z","iopub.status.idle":"2024-11-15T13:19:54.309500Z","shell.execute_reply.started":"2024-11-15T13:19:54.298562Z","shell.execute_reply":"2024-11-15T13:19:54.308486Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"# TRANSFORMER ","metadata":{}},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n        super(Transformer, self).__init__()\n        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n\n        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n\n        self.fc = nn.Linear(d_model, tgt_vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def generate_mask(self, src, tgt):\n        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n        seq_length = tgt.size(1)\n        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n        tgt_mask = tgt_mask & nopeak_mask\n        return src_mask, tgt_mask\n\n    def forward(self, src, tgt):\n        src_mask, tgt_mask = self.generate_mask(src, tgt)\n        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n\n        enc_output = src_embedded\n        for enc_layer in self.encoder_layers:\n            enc_output = enc_layer(enc_output, src_mask)\n\n        dec_output = tgt_embedded\n        for dec_layer in self.decoder_layers:\n            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n\n        output = self.fc(dec_output)\n        return output\n\ntransformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:54.383154Z","iopub.execute_input":"2024-11-15T13:19:54.383683Z","iopub.status.idle":"2024-11-15T13:19:55.122463Z","shell.execute_reply.started":"2024-11-15T13:19:54.383638Z","shell.execute_reply":"2024-11-15T13:19:55.121396Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# TRAINING THE MODEL","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=0)\noptimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n\ntransformer.train()\n\nfor epoch in range(100):\n    optimizer.zero_grad()\n    output = transformer(src_data, tgt_data[:, :-1])\n    loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n    loss.backward()\n    optimizer.step()\n    print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-15T13:19:55.124760Z","iopub.execute_input":"2024-11-15T13:19:55.125761Z","iopub.status.idle":"2024-11-15T13:47:56.072172Z","shell.execute_reply.started":"2024-11-15T13:19:55.125683Z","shell.execute_reply":"2024-11-15T13:47:56.070952Z"}},"outputs":[{"name":"stdout","text":"Epoch: 1, Loss: 8.674042701721191\nEpoch: 2, Loss: 8.551736831665039\nEpoch: 3, Loss: 8.481254577636719\nEpoch: 4, Loss: 8.427270889282227\nEpoch: 5, Loss: 8.375389099121094\nEpoch: 6, Loss: 8.309242248535156\nEpoch: 7, Loss: 8.225054740905762\nEpoch: 8, Loss: 8.145411491394043\nEpoch: 9, Loss: 8.062606811523438\nEpoch: 10, Loss: 7.985562324523926\nEpoch: 11, Loss: 7.908583641052246\nEpoch: 12, Loss: 7.820342063903809\nEpoch: 13, Loss: 7.743888854980469\nEpoch: 14, Loss: 7.663418292999268\nEpoch: 15, Loss: 7.578866004943848\nEpoch: 16, Loss: 7.4917216300964355\nEpoch: 17, Loss: 7.40960693359375\nEpoch: 18, Loss: 7.331147193908691\nEpoch: 19, Loss: 7.238668441772461\nEpoch: 20, Loss: 7.170829772949219\nEpoch: 21, Loss: 7.084386825561523\nEpoch: 22, Loss: 7.018468856811523\nEpoch: 23, Loss: 6.950435638427734\nEpoch: 24, Loss: 6.865726947784424\nEpoch: 25, Loss: 6.788518905639648\nEpoch: 26, Loss: 6.707488059997559\nEpoch: 27, Loss: 6.633789539337158\nEpoch: 28, Loss: 6.559695243835449\nEpoch: 29, Loss: 6.499029636383057\nEpoch: 30, Loss: 6.424808502197266\nEpoch: 31, Loss: 6.351099491119385\nEpoch: 32, Loss: 6.287037372589111\nEpoch: 33, Loss: 6.214633941650391\nEpoch: 34, Loss: 6.1490631103515625\nEpoch: 35, Loss: 6.077402591705322\nEpoch: 36, Loss: 6.01798152923584\nEpoch: 37, Loss: 5.947383403778076\nEpoch: 38, Loss: 5.881694316864014\nEpoch: 39, Loss: 5.819110870361328\nEpoch: 40, Loss: 5.757030963897705\nEpoch: 41, Loss: 5.694509029388428\nEpoch: 42, Loss: 5.636510848999023\nEpoch: 43, Loss: 5.572272300720215\nEpoch: 44, Loss: 5.514349937438965\nEpoch: 45, Loss: 5.453073978424072\nEpoch: 46, Loss: 5.390279769897461\nEpoch: 47, Loss: 5.332462310791016\nEpoch: 48, Loss: 5.274296283721924\nEpoch: 49, Loss: 5.214482307434082\nEpoch: 50, Loss: 5.155172824859619\nEpoch: 51, Loss: 5.096011638641357\nEpoch: 52, Loss: 5.040216445922852\nEpoch: 53, Loss: 4.985324382781982\nEpoch: 54, Loss: 4.930192470550537\nEpoch: 55, Loss: 4.876075744628906\nEpoch: 56, Loss: 4.823512077331543\nEpoch: 57, Loss: 4.775402069091797\nEpoch: 58, Loss: 4.716444969177246\nEpoch: 59, Loss: 4.659408092498779\nEpoch: 60, Loss: 4.613363742828369\nEpoch: 61, Loss: 4.556318283081055\nEpoch: 62, Loss: 4.507486343383789\nEpoch: 63, Loss: 4.4572529792785645\nEpoch: 64, Loss: 4.39823579788208\nEpoch: 65, Loss: 4.3565826416015625\nEpoch: 66, Loss: 4.300446510314941\nEpoch: 67, Loss: 4.249720573425293\nEpoch: 68, Loss: 4.203532695770264\nEpoch: 69, Loss: 4.151172637939453\nEpoch: 70, Loss: 4.098154067993164\nEpoch: 71, Loss: 4.052727699279785\nEpoch: 72, Loss: 3.999021530151367\nEpoch: 73, Loss: 3.9540953636169434\nEpoch: 74, Loss: 3.905719518661499\nEpoch: 75, Loss: 3.8559682369232178\nEpoch: 76, Loss: 3.8036887645721436\nEpoch: 77, Loss: 3.7609193325042725\nEpoch: 78, Loss: 3.71463680267334\nEpoch: 79, Loss: 3.6740336418151855\nEpoch: 80, Loss: 3.6262028217315674\nEpoch: 81, Loss: 3.57364821434021\nEpoch: 82, Loss: 3.5270326137542725\nEpoch: 83, Loss: 3.4758493900299072\nEpoch: 84, Loss: 3.433894634246826\nEpoch: 85, Loss: 3.384183406829834\nEpoch: 86, Loss: 3.3437814712524414\nEpoch: 87, Loss: 3.29964017868042\nEpoch: 88, Loss: 3.2613375186920166\nEpoch: 89, Loss: 3.212869644165039\nEpoch: 90, Loss: 3.1616296768188477\nEpoch: 91, Loss: 3.1140832901000977\nEpoch: 92, Loss: 3.070047616958618\nEpoch: 93, Loss: 3.025157928466797\nEpoch: 94, Loss: 2.9866414070129395\nEpoch: 95, Loss: 2.9445602893829346\nEpoch: 96, Loss: 2.897162437438965\nEpoch: 97, Loss: 2.8670835494995117\nEpoch: 98, Loss: 2.821787118911743\nEpoch: 99, Loss: 2.77761173248291\nEpoch: 100, Loss: 2.741583824157715\n","output_type":"stream"}],"execution_count":13}]}